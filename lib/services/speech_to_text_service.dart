import 'dart:convert';
import 'dart:io';
import 'package:get/get.dart';
import 'package:http/http.dart' as http;
import 'package:path_provider/path_provider.dart';
import '../models/transcribed_audio.dart';
import '../core/config/env_config.dart';
import 'gemini_service.dart';

class SpeechToTextService {
  final List<TranscribedAudio> _transcriptions = [];

  List<TranscribedAudio> get transcriptions => _transcriptions;

  // Gemini API for text processing
  static String get _geminiApiKey => EnvConfig.googleAIApiKey;
  static const String _geminiBaseUrl = 'https://generativelanguage.googleapis.com/v1beta';

  // GeminiService for AI features
  GeminiService? get _geminiService {
    try {
      return Get.find<GeminiService>();
    } catch (e) {
      return null;
    }
  }

  bool get _useGemini => _geminiService?.isConfigured ?? false;

  /// ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
  Future<TranscribedAudio> transcribeAudioFile({
    required String audioPath,
    String language = 'ar',
    String? title,
  }) async {
    try {
      String transcribedText;
      int duration = 0;

      // Try Gemini audio transcription
      if (_geminiApiKey.isNotEmpty) {
        print('ğŸ¤ Transcribing audio with Gemini...');
        transcribedText = await _transcribeWithGemini(audioPath, language);

        // Estimate duration from file size
        final file = File(audioPath);
        if (await file.exists()) {
          final fileSize = await file.length();
          duration = (fileSize / 16000).round(); // Rough estimate for audio
        }
      } else {
        // Fallback to demo mode
        print('âš ï¸ Gemini API key not configured, using demo mode');
        await Future.delayed(const Duration(seconds: 2));
        transcribedText = _generateDemoTranscription(language);
        duration = 45;
      }

      final segments = _generateSegmentsFromText(transcribedText);

      final transcription = TranscribedAudio(
        id: DateTime.now().millisecondsSinceEpoch.toString(),
        audioPath: audioPath,
        transcribedText: transcribedText,
        createdAt: DateTime.now(),
        duration: duration,
        language: language,
        title: title ?? 'ØªØ³Ø¬ÙŠÙ„ ${_transcriptions.length + 1}',
        segments: segments,
        confidence: 0.95,
        source: AudioSource.file,
      );

      _transcriptions.insert(0, transcription);
      return transcription;
    } catch (e) {
      throw Exception('Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ: $e');
    }
  }

  /// Transcribe audio using Gemini API
  Future<String> _transcribeWithGemini(String audioPath, String language) async {
    try {
      final file = File(audioPath);
      if (!await file.exists()) {
        throw Exception('Audio file not found');
      }

      final bytes = await file.readAsBytes();
      final base64Audio = base64Encode(bytes);

      // Detect mime type from extension
      final extension = audioPath.split('.').last.toLowerCase();
      String mimeType;
      switch (extension) {
        case 'mp3':
          mimeType = 'audio/mp3';
          break;
        case 'wav':
          mimeType = 'audio/wav';
          break;
        case 'm4a':
          mimeType = 'audio/mp4';
          break;
        case 'ogg':
          mimeType = 'audio/ogg';
          break;
        case 'flac':
          mimeType = 'audio/flac';
          break;
        default:
          mimeType = 'audio/mpeg';
      }

      final langName = language == 'ar' ? 'Arabic' : 'English';

      final response = await http.post(
        Uri.parse('$_geminiBaseUrl/models/gemini-2.0-flash-exp:generateContent?key=$_geminiApiKey'),
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode({
          'contents': [
            {
              'parts': [
                {
                  'inlineData': {
                    'mimeType': mimeType,
                    'data': base64Audio,
                  }
                },
                {
                  'text': '''Transcribe this audio file accurately.
The audio is in $langName language.
Provide only the transcription without any additional commentary.
Include proper punctuation and paragraph breaks where appropriate.'''
                }
              ]
            }
          ],
          'generationConfig': {
            'temperature': 0.1,
            'maxOutputTokens': 8192,
          }
        }),
      );

      if (response.statusCode == 200) {
        final data = jsonDecode(response.body);
        final text = data['candidates']?[0]?['content']?['parts']?[0]?['text'];
        if (text != null && text.isNotEmpty) {
          print('âœ… Gemini transcription successful');
          return text;
        }
        throw Exception('Empty response from Gemini');
      } else {
        print('âŒ Gemini transcription failed: ${response.statusCode}');
        print('Response: ${response.body}');
        throw Exception('Gemini transcription failed: ${response.statusCode}');
      }
    } catch (e) {
      print('âŒ Error in Gemini transcription: $e');
      rethrow;
    }
  }

  /// Generate segments from transcribed text
  List<AudioSegment> _generateSegmentsFromText(String text) {
    final sentences = text.split(RegExp(r'[.!?ØŒØŸ]\s+'));
    final segments = <AudioSegment>[];
    int currentTime = 0;

    for (int i = 0; i < sentences.length; i++) {
      if (sentences[i].trim().isEmpty) continue;

      final duration = (sentences[i].length / 8).round() * 1000; // Estimate ~8 chars per second
      segments.add(
        AudioSegment(
          startTime: currentTime,
          endTime: currentTime + duration,
          text: sentences[i].trim(),
          confidence: 0.90 + (i % 10) * 0.01,
        ),
      );
      currentTime += duration;
    }

    return segments;
  }

  /// ØªØ­ÙˆÙŠÙ„ ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ Ø¥Ù„Ù‰ Ù†Øµ
  Future<TranscribedAudio> transcribeRecording({
    required String recordingPath,
    String language = 'ar',
    String? title,
  }) async {
    try {
      String transcribedText;
      int duration = 0;

      // Try Gemini audio transcription
      if (_geminiApiKey.isNotEmpty) {
        print('ğŸ¤ Transcribing recording with Gemini...');
        transcribedText = await _transcribeWithGemini(recordingPath, language);

        // Estimate duration from file size
        final file = File(recordingPath);
        if (await file.exists()) {
          final fileSize = await file.length();
          duration = (fileSize / 16000).round();
        }
      } else {
        // Fallback to demo mode
        print('âš ï¸ Gemini API key not configured, using demo mode');
        await Future.delayed(const Duration(seconds: 2));
        transcribedText = _generateDemoTranscription(language);
        duration = 30;
      }

      final segments = _generateSegmentsFromText(transcribedText);

      final transcription = TranscribedAudio(
        id: DateTime.now().millisecondsSinceEpoch.toString(),
        audioPath: recordingPath,
        transcribedText: transcribedText,
        createdAt: DateTime.now(),
        duration: duration,
        language: language,
        title: title ?? 'ØªØ³Ø¬ÙŠÙ„ ${_transcriptions.length + 1}',
        segments: segments,
        confidence: 0.92,
        source: AudioSource.recording,
      );

      _transcriptions.insert(0, transcription);
      return transcription;
    } catch (e) {
      throw Exception('Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ: $e');
    }
  }

  /// ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Gemini)
  Future<String> improveText(String text, String language) async {
    try {
      // Try using GeminiService first
      if (_useGemini) {
        print('âœ¨ Improving text with GeminiService...');
        return await _geminiService!.improveContent(content: text);
      }

      // Try direct Gemini API
      if (_geminiApiKey.isNotEmpty) {
        print('âœ¨ Improving text with Gemini API...');
        return await _improveTextWithGemini(text, language);
      }

      // Fallback to demo mode
      print('âš ï¸ Gemini not configured, using demo mode');
      await Future.delayed(const Duration(seconds: 1));

      if (language == 'ar') {
        return '''$text

[ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Øµ]:
â€¢ Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
â€¢ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©
â€¢ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙŠØ§ØºØ© ÙˆØ§Ù„ØªÙ†Ø³ÙŠÙ‚
''';
      } else {
        return '''$text

[Text improved]:
â€¢ Added proper punctuation
â€¢ Fixed spelling errors
â€¢ Improved formatting and structure
''';
      }
    } catch (e) {
      throw Exception('Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Øµ: $e');
    }
  }

  /// Improve text using direct Gemini API
  Future<String> _improveTextWithGemini(String text, String language) async {
    final langInstructions = language == 'ar'
        ? 'Ø£Ù†Øª Ù…Ø­Ø±Ø± Ù†ØµÙˆØµ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† Ø®Ù„Ø§Ù„: Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©ØŒ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©ØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙŠØ§ØºØ© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø£ØµÙ„ÙŠ. Ù‚Ø¯Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­Ø³Ù† ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ØªØ¹Ù„ÙŠÙ‚Ø§Øª.'
        : 'You are a professional text editor. Improve the following text by: adding proper punctuation, fixing spelling errors, and improving the structure while preserving the original meaning. Provide only the improved text without any comments.';

    final response = await http.post(
      Uri.parse('$_geminiBaseUrl/models/gemini-1.5-flash:generateContent?key=$_geminiApiKey'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({
        'contents': [
          {
            'parts': [
              {'text': '$langInstructions\n\nØ§Ù„Ù†Øµ:\n$text'}
            ]
          }
        ],
        'generationConfig': {
          'temperature': 0.3,
          'maxOutputTokens': 4096,
        }
      }),
    );

    if (response.statusCode == 200) {
      final data = jsonDecode(response.body);
      final result = data['candidates']?[0]?['content']?['parts']?[0]?['text'];
      if (result != null && result.isNotEmpty) {
        print('âœ… Text improved successfully');
        return result;
      }
    }
    throw Exception('Failed to improve text: ${response.statusCode}');
  }

  /// ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
  Future<String> summarizeText(String text, String language) async {
    try {
      // Try direct Gemini API
      if (_geminiApiKey.isNotEmpty) {
        print('ğŸ“ Summarizing text with Gemini...');
        return await _summarizeWithGemini(text, language);
      }

      // Fallback to demo mode
      print('âš ï¸ Gemini not configured, using demo mode');
      await Future.delayed(const Duration(seconds: 1));

      if (language == 'ar') {
        return 'Ù…Ù„Ø®Øµ Ø§Ù„Ù†Øµ:\n\nÙ‡Ø°Ø§ Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ ÙŠÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ø¹Ù…Ù„ Ù…ÙŠØ²Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ. ÙŠØªØ¶Ù…Ù† Ø§Ù„Ù†Øµ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù…Ø© Ø­ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø·Ø±ÙˆØ­ Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©.';
      } else {
        return 'Text Summary:\n\nThis is a demo text showing how the speech-to-text feature works. The text includes important information about the subject with practical examples.';
      }
    } catch (e) {
      throw Exception('Ø®Ø·Ø£ ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ: $e');
    }
  }

  /// Summarize text using Gemini API
  Future<String> _summarizeWithGemini(String text, String language) async {
    final langInstructions = language == 'ar'
        ? 'Ù‚Ù… Ø¨ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø´ÙƒÙ„ Ù…ÙˆØ¬Ø² ÙˆÙ…ÙÙŠØ¯. Ù‚Ø¯Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ ÙÙ‚Ø±Ø© Ø£Ùˆ ÙÙ‚Ø±ØªÙŠÙ†.'
        : 'Summarize the following text concisely and meaningfully. Present the main points in one or two paragraphs.';

    final response = await http.post(
      Uri.parse('$_geminiBaseUrl/models/gemini-1.5-flash:generateContent?key=$_geminiApiKey'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({
        'contents': [
          {
            'parts': [
              {'text': '$langInstructions\n\nØ§Ù„Ù†Øµ:\n$text'}
            ]
          }
        ],
        'generationConfig': {
          'temperature': 0.3,
          'maxOutputTokens': 1024,
        }
      }),
    );

    if (response.statusCode == 200) {
      final data = jsonDecode(response.body);
      final result = data['candidates']?[0]?['content']?['parts']?[0]?['text'];
      if (result != null && result.isNotEmpty) {
        print('âœ… Text summarized successfully');
        return result;
      }
    }
    throw Exception('Failed to summarize text: ${response.statusCode}');
  }

  /// Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
  Future<List<String>> extractKeywords(String text, String language) async {
    try {
      // Try direct Gemini API
      if (_geminiApiKey.isNotEmpty) {
        print('ğŸ”‘ Extracting keywords with Gemini...');
        return await _extractKeywordsWithGemini(text, language);
      }

      // Fallback to demo mode
      print('âš ï¸ Gemini not configured, using demo mode');
      await Future.delayed(const Duration(seconds: 1));

      if (language == 'ar') {
        return [
          'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ',
          'ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª',
          'Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ',
          'Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§',
          'Ø§Ù„Ø§Ø¨ØªÙƒØ§Ø±',
        ];
      } else {
        return [
          'artificial intelligence',
          'speech-to-text',
          'machine learning',
          'technology',
          'innovation',
        ];
      }
    } catch (e) {
      throw Exception('Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: $e');
    }
  }

  /// Extract keywords using Gemini API
  Future<List<String>> _extractKeywordsWithGemini(String text, String language) async {
    final langInstructions = language == 'ar'
        ? 'Ø§Ø³ØªØ®Ø±Ø¬ 5-10 ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ. Ù‚Ø¯Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø·ØŒ ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ Ø³Ø·Ø± Ù…Ù†ÙØµÙ„ØŒ Ø¨Ø¯ÙˆÙ† ØªØ±Ù‚ÙŠÙ… Ø£Ùˆ Ø±Ù…ÙˆØ².'
        : 'Extract 5-10 keywords from the following text. Provide only the keywords, each on a separate line, without numbering or symbols.';

    final response = await http.post(
      Uri.parse('$_geminiBaseUrl/models/gemini-1.5-flash:generateContent?key=$_geminiApiKey'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({
        'contents': [
          {
            'parts': [
              {'text': '$langInstructions\n\nØ§Ù„Ù†Øµ:\n$text'}
            ]
          }
        ],
        'generationConfig': {
          'temperature': 0.2,
          'maxOutputTokens': 256,
        }
      }),
    );

    if (response.statusCode == 200) {
      final data = jsonDecode(response.body);
      final result = data['candidates']?[0]?['content']?['parts']?[0]?['text'];
      if (result != null && result.isNotEmpty) {
        print('âœ… Keywords extracted successfully');
        return result
            .split('\n')
            .map((s) => s.trim())
            .where((s) => s.isNotEmpty && !s.startsWith('-') && !RegExp(r'^\d+\.').hasMatch(s))
            .map((s) => s.replaceAll(RegExp(r'^[-â€¢]\s*'), ''))
            .toList();
      }
    }
    throw Exception('Failed to extract keywords: ${response.statusCode}');
  }

  /// ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ÙˆØ§Ù† Ø°ÙƒÙŠ Ù„Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
  Future<String> generateSmartTitle(String text, String language) async {
    try {
      // Try direct Gemini API
      if (_geminiApiKey.isNotEmpty) {
        print('ğŸ’¡ Generating smart title with Gemini...');
        return await _generateTitleWithGemini(text, language);
      }

      // Fallback to demo mode
      print('âš ï¸ Gemini not configured, using demo mode');
      await Future.delayed(const Duration(seconds: 1));

      final timestamp = DateTime.now();
      if (language == 'ar') {
        return 'Ù†Øµ Ù…ÙØ­ÙˆÙ„ Ø¨ØªØ§Ø±ÙŠØ® ${timestamp.day}/${timestamp.month}/${timestamp.year}';
      } else {
        return 'Transcribed Text - ${timestamp.day}/${timestamp.month}/${timestamp.year}';
      }
    } catch (e) {
      throw Exception('Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: $e');
    }
  }

  /// Generate smart title using Gemini API
  Future<String> _generateTitleWithGemini(String text, String language) async {
    final langInstructions = language == 'ar'
        ? 'Ø§Ù‚ØªØ±Ø­ Ø¹Ù†ÙˆØ§Ù†Ø§Ù‹ Ù‚ØµÙŠØ±Ø§Ù‹ ÙˆØ¬Ø°Ø§Ø¨Ø§Ù‹ (3-7 ÙƒÙ„Ù…Ø§Øª) Ù„Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ. Ù‚Ø¯Ù… Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø¹Ù„Ø§Ù…Ø§Øª ØªØ±Ù‚ÙŠÙ… Ø¥Ø¶Ø§ÙÙŠØ©.'
        : 'Suggest a short and engaging title (3-7 words) for the following text. Provide only the title without any additional punctuation.';

    final response = await http.post(
      Uri.parse('$_geminiBaseUrl/models/gemini-1.5-flash:generateContent?key=$_geminiApiKey'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({
        'contents': [
          {
            'parts': [
              {'text': '$langInstructions\n\nØ§Ù„Ù†Øµ:\n$text'}
            ]
          }
        ],
        'generationConfig': {
          'temperature': 0.5,
          'maxOutputTokens': 64,
        }
      }),
    );

    if (response.statusCode == 200) {
      final data = jsonDecode(response.body);
      final result = data['candidates']?[0]?['content']?['parts']?[0]?['text'];
      if (result != null && result.isNotEmpty) {
        print('âœ… Title generated successfully');
        return result.trim().replaceAll('"', '').replaceAll("'", '');
      }
    }

    // Fallback to timestamp-based title
    final timestamp = DateTime.now();
    if (language == 'ar') {
      return 'Ù†Øµ Ù…ÙØ­ÙˆÙ„ Ø¨ØªØ§Ø±ÙŠØ® ${timestamp.day}/${timestamp.month}/${timestamp.year}';
    } else {
      return 'Transcribed Text - ${timestamp.day}/${timestamp.month}/${timestamp.year}';
    }
  }

  String _generateDemoTranscription(String language) {
    if (language == 'ar') {
      return '''Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ù‡Ø°Ø§ Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡ Ù„Ø¥Ø¸Ù‡Ø§Ø± ÙƒÙŠÙÙŠØ© Ø¹Ù…Ù„ Ù…ÙŠØ²Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ.

ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†ØµØŒ Ù†Ø³ØªØ¹Ø±Ø¶ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø©:

Ø£ÙˆÙ„Ø§Ù‹: ØªÙ‚Ù†ÙŠØ© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø£ØµØ¨Ø­Øª Ù…Ù† Ø£Ù‡Ù… Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª ÙÙŠ Ø¹ØµØ±Ù†Ø§ Ø§Ù„Ø­Ø§Ù„ÙŠ. Ø­ÙŠØ« ØªØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ ØªÙˆÙÙŠØ± Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ø¬Ù‡Ø¯ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰.

Ø«Ø§Ù†ÙŠØ§Ù‹: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØ¬Ø¹Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø© ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©. ÙƒÙ…Ø§ ÙŠÙ…ÙƒÙ†Ù‡ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.

Ø«Ø§Ù„Ø«Ø§Ù‹: Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù…ÙÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØµØ­ÙÙŠÙŠÙ†ØŒ ÙˆØ§Ù„ÙƒØªÙ‘Ø§Ø¨ØŒ ÙˆØ§Ù„Ø·Ù„Ø§Ø¨ØŒ ÙˆÙ…Ù†Ø´Ø¦ÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ.

ÙÙŠ Ø§Ù„Ø®ØªØ§Ù…ØŒ Ù†Ø£Ù…Ù„ Ø£Ù† ØªÙƒÙˆÙ† Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø© Ù…ÙÙŠØ¯Ø© Ù„Ùƒ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¨Ø³Ù‡ÙˆÙ„Ø© ÙˆØ³Ø±Ø¹Ø©.''';
    } else {
      return '''Hello, this is a demo text generated to show how the speech-to-text feature works.

In this text, we explore several important points:

First: Speech-to-text technology has become one of the most important technologies in our current era. It helps save time and effort in content creation.

Second: Using artificial intelligence makes the conversion process more accurate and professional. It can also automatically correct errors.

Third: This technology is very useful for journalists, writers, students, and social media content creators.

In conclusion, we hope this feature will be useful for you in creating professional content easily and quickly.''';
    }
  }

  List<AudioSegment> _generateDemoSegments(String text) {
    final sentences = text.split('\n\n');
    final segments = <AudioSegment>[];
    int currentTime = 0;

    for (int i = 0; i < sentences.length; i++) {
      final duration =
          (sentences[i].length / 10).round() * 1000; // ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ
      segments.add(
        AudioSegment(
          startTime: currentTime,
          endTime: currentTime + duration,
          text: sentences[i],
          confidence: 0.90 + (i % 10) * 0.01,
        ),
      );
      currentTime += duration;
    }

    return segments;
  }

  /// Ø­Ø°Ù Ù†Ø³Ø®Ø©
  void deleteTranscription(String id) {
    _transcriptions.removeWhere((t) => t.id == id);
  }

  /// Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ø³Ø®
  void clearAllTranscriptions() {
    _transcriptions.clear();
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© Ø¨ÙˆØ§Ø³Ø·Ø© ID
  TranscribedAudio? getTranscriptionById(String id) {
    try {
      return _transcriptions.firstWhere((t) => t.id == id);
    } catch (e) {
      return null;
    }
  }

  /// ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù„Ù
  Future<String> exportToFile(
    TranscribedAudio transcription,
    String format,
  ) async {
    try {
      final directory = await getApplicationDocumentsDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      final fileName = '${transcription.title}_$timestamp.$format';
      final filePath = '${directory.path}/$fileName';

      final file = File(filePath);

      switch (format.toLowerCase()) {
        case 'txt':
          await file.writeAsString(transcription.transcribedText);
          break;
        case 'json':
          await file.writeAsString(jsonEncode(transcription.toJson()));
          break;
        case 'srt':
          // ØªÙ†Ø³ÙŠÙ‚ ØªØ±Ø¬Ù…Ø§Øª SRT
          final srtContent = _generateSRTContent(transcription.segments);
          await file.writeAsString(srtContent);
          break;
        default:
          await file.writeAsString(transcription.transcribedText);
      }

      return filePath;
    } catch (e) {
      throw Exception('ÙØ´Ù„ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù„Ù: $e');
    }
  }

  String _generateSRTContent(List<AudioSegment> segments) {
    final buffer = StringBuffer();
    for (int i = 0; i < segments.length; i++) {
      buffer.writeln('${i + 1}');
      buffer.writeln(
        '${_formatSRTTime(segments[i].startTime)} --> ${_formatSRTTime(segments[i].endTime)}',
      );
      buffer.writeln(segments[i].text);
      buffer.writeln();
    }
    return buffer.toString();
  }

  String _formatSRTTime(int milliseconds) {
    final duration = Duration(milliseconds: milliseconds);
    final hours = duration.inHours.toString().padLeft(2, '0');
    final minutes = (duration.inMinutes % 60).toString().padLeft(2, '0');
    final seconds = (duration.inSeconds % 60).toString().padLeft(2, '0');
    final millis = (duration.inMilliseconds % 1000).toString().padLeft(3, '0');
    return '$hours:$minutes:$seconds,$millis';
  }
}
